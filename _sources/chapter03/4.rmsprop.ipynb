{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSprop\n",
    "\n",
    "梯度下降 $\\mathbf{x}_{t} = \\mathbf{x}_{t-1} - \\eta\\mathbf{g}_{t}$ 中学习率是固定的。\n",
    "\n",
    "但我们期望学习率可变：在参数空间更为平缓的区域，学习率高一些；参数空间更为陡峭的区域，学习率低一些。\n",
    "\n",
    "由这个思路可以导出 RMSprop：\n",
    "\n",
    "$$\\mathbf{s}_{t} = \\alpha\\mathbf{s}_{t-1} + (1 - \\alpha)\\mathbf{g}_{t}^{2}$$\n",
    "\n",
    "$$\\mathbf{x}_{t} = \\mathbf{x}_{t-1} - \\frac{\\eta}{\\sqrt{\\mathbf{s}_{t}} + \\epsilon}\\odot\\mathbf{g}_{t}$$\n",
    "\n",
    "由 $\\mathbf{s}_{t}$ 即梯度平方的 moving average 反映近期梯度的大小，它高学习率就低，它低学习率就高，每一步跨度差不多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(784, 10))\n",
    "# pytorch中的RMSprop\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01, alpha=0.99)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
