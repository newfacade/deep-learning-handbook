{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预训练+微调\n",
    "\n",
    "```{note}\n",
    "使用预训练模型就像是站在巨人的肩膀上，现在很多模型都是预训练+微调的模式。<br/>\n",
    "本节我们使用在Fashion-MNIST上训练好的模型来训练MNIST。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获得模型和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# 之前在Fashion-MNIST上训练的模型\n",
    "model_A = keras.models.load_model(\"my_fashion_mnist_model\")\n",
    "# 前面用预训练的数据，最后一层从头开始\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(10, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入MNIST数据集\n",
    "(X_train_val, y_train_val), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_val, X_train = X_train_val[:5000] / 255., X_train_val[5000:] / 255.\n",
    "y_val, y_train = y_train_val[:5000], y_train_val[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 冻结预训练层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 2s 887us/step - loss: 1.4689 - accuracy: 0.5684 - val_loss: 1.1026 - val_accuracy: 0.7056\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 1s 809us/step - loss: 1.0053 - accuracy: 0.7226 - val_loss: 0.9022 - val_accuracy: 0.7530\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 1s 805us/step - loss: 0.8703 - accuracy: 0.7576 - val_loss: 0.8063 - val_accuracy: 0.7794\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 1s 814us/step - loss: 0.7954 - accuracy: 0.7759 - val_loss: 0.7435 - val_accuracy: 0.8024\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 1s 818us/step - loss: 0.7451 - accuracy: 0.7887 - val_loss: 0.7010 - val_accuracy: 0.8128\n"
     ]
    }
   ],
   "source": [
    "# 冻结pretrain layers\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 编译\n",
    "model_B_on_A.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "                     metrics=[\"accuracy\"])\n",
    "# 训练\n",
    "history = model_B_on_A.fit(X_train, y_train, \n",
    "                           epochs=5,\n",
    "                           validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微调预训练层\n",
    "\n",
    "在冻结预训练层进行训练后，我们可以放开限制进行微调，注意微调时要用较小的学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5269 - accuracy: 0.8498 - val_loss: 0.4049 - val_accuracy: 0.8918\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3861 - accuracy: 0.8912 - val_loss: 0.3336 - val_accuracy: 0.9094\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3340 - accuracy: 0.9055 - val_loss: 0.2983 - val_accuracy: 0.9196\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3036 - accuracy: 0.9142 - val_loss: 0.2760 - val_accuracy: 0.9248\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2822 - accuracy: 0.9202 - val_loss: 0.2600 - val_accuracy: 0.9284\n"
     ]
    }
   ],
   "source": [
    "# 解冻\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# 使用较小的学习率重新编译\n",
    "model_B_on_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "# 训练\n",
    "history = model_B_on_A.fit(X_train, y_train, \n",
    "                           epochs=5,\n",
    "                           validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
